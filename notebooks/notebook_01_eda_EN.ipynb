{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# ğŸ¦ Credit Risk Scorecard â€” Notebook 1: Exploratory Data Analysis (EDA) & Data Cleaning\n",
    "\n",
    "**Project:** Credit Risk Scorecard + IFRS 9 Expected Credit Loss (ECL) Engine  \n",
    "**Dataset:** Give Me Some Credit â€” Kaggle Competition Data  \n",
    "**Objective:** Predict the probability that a borrower will experience serious financial distress within the next two years (foundation for the PD model)\n",
    "\n",
    "**Author:** *Your Name*  \n",
    "**Date:** *2026*\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ Notebook Contents\n",
    "1. Load data & inspect structure\n",
    "2. Target variable analysis (default rate)\n",
    "3. Handle missing values\n",
    "4. Handle outliers\n",
    "5. Feature distribution visualisation\n",
    "6. Correlation analysis\n",
    "7. Save cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step0",
   "metadata": {},
   "source": [
    "## Step 0: Upload Data File (Google Colab Only)\n",
    "\n",
    "If running in **Google Colab**, uncomment and run the cell below to upload `cs-training.csv`.  \n",
    "If running locally, make sure `cs-training.csv` is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below if running in Google Colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # Select cs-training.csv from your local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Core libraries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot styling\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print('All libraries imported successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Load raw training data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv('cs-training.csv', index_col=0)\n",
    "\n",
    "print(f'Dataset loaded successfully.')\n",
    "print(f'Shape: {df.shape[0]:,} rows  x  {df.shape[1]} columns')\n",
    "print()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Rename columns for readability â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df.columns = [\n",
    "    'default',           # Target: serious delinquency in next 2 years (1=yes, 0=no)\n",
    "    'revolving_util',    # Revolving credit utilisation rate\n",
    "    'age',               # Borrower age\n",
    "    'late_30_59',        # Number of times 30-59 days past due\n",
    "    'debt_ratio',        # Monthly debt payments / monthly gross income\n",
    "    'monthly_income',    # Monthly gross income\n",
    "    'open_credit_lines', # Number of open credit lines and loans\n",
    "    'late_90',           # Number of times 90+ days past due\n",
    "    'real_estate_loans', # Number of real estate loans or lines\n",
    "    'late_60_89',        # Number of times 60-89 days past due\n",
    "    'dependents'         # Number of dependents\n",
    "]\n",
    "\n",
    "print('Columns renamed:')\n",
    "for col in df.columns:\n",
    "    print(f'  Â· {col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "## Step 2: Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Data types, missing values, unique counts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "info_df = pd.DataFrame({\n",
    "    'dtype': df.dtypes,\n",
    "    'missing_count': df.isnull().sum(),\n",
    "    'missing_pct': (df.isnull().sum() / len(df) * 100).round(2).astype(str) + '%',\n",
    "    'unique_values': df.nunique()\n",
    "})\n",
    "\n",
    "print('=== Data Overview ===')\n",
    "print(info_df)\n",
    "print()\n",
    "print(f'Columns with missing values: {df.isnull().any().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "describe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Descriptive statistics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('=== Descriptive Statistics ===')\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "## Step 3: Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Default rate summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "default_counts = df['default'].value_counts()\n",
    "default_rate = df['default'].mean() * 100\n",
    "\n",
    "print('=== Target Variable: default ===')\n",
    "print(f'Non-default (0): {default_counts[0]:,}  ({100 - default_rate:.1f}%)')\n",
    "print(f'Default     (1): {default_counts[1]:,}  ({default_rate:.1f}%)')\n",
    "print(f'\\nOverall default rate : {default_rate:.2f}%')\n",
    "print(f'Class imbalance ratio: ~1:{int(default_counts[0]/default_counts[1])}  (default : non-default)')\n",
    "\n",
    "# â”€â”€ Plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "# Bar chart\n",
    "axes[0].bar(['Non-Default (0)', 'Default (1)'], default_counts.values,\n",
    "            color=colors, edgecolor='white', linewidth=1.5)\n",
    "axes[0].set_title('Default Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Borrowers')\n",
    "for i, v in enumerate(default_counts.values):\n",
    "    axes[0].text(i, v + 500, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(\n",
    "    default_counts.values,\n",
    "    labels=[f'Non-Default\\n{100-default_rate:.1f}%', f'Default\\n{default_rate:.1f}%'],\n",
    "    colors=colors, startangle=90,\n",
    "    wedgeprops={'edgecolor': 'white', 'linewidth': 2}\n",
    ")\n",
    "axes[1].set_title('Default Rate', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Target Variable Distribution', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_01_target_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_01_target_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "## Step 4: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Visualise missing values â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "bars = plt.bar(missing.index, missing.values / len(df) * 100,\n",
    "               color='#e74c3c', alpha=0.8)\n",
    "plt.title('Missing Value Rate by Column', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Missing Rate (%)')\n",
    "plt.xticks(rotation=15)\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,\n",
    "             f'{bar.get_height():.1f}%', ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_02_missing_values.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_02_missing_values.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fill-missing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Impute missing values with median â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Median is preferred over mean for skewed distributions (e.g. income)\n",
    "\n",
    "income_median = df['monthly_income'].median()\n",
    "df['monthly_income'].fillna(income_median, inplace=True)\n",
    "print(f'monthly_income: imputed with median = {income_median:,.0f}')\n",
    "\n",
    "dep_median = df['dependents'].median()\n",
    "df['dependents'].fillna(dep_median, inplace=True)\n",
    "print(f'dependents    : imputed with median = {dep_median:.0f}')\n",
    "\n",
    "print()\n",
    "print(f'Remaining missing values: {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5",
   "metadata": {},
   "source": [
    "## Step 5: Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outliers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Outlier detection & treatment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('=== Outlier Treatment ===')\n",
    "\n",
    "# 1. Age â€” remove implausible values\n",
    "print(f'age < 18 : {(df[\"age\"] < 18).sum()} records')\n",
    "print(f'age > 100: {(df[\"age\"] > 100).sum()} records')\n",
    "before = len(df)\n",
    "df = df[(df['age'] >= 18) & (df['age'] <= 100)]\n",
    "print(f'  â†’ Removed {before - len(df)} records with implausible age\\n')\n",
    "\n",
    "# 2. revolving_util â€” clip to [0, 1] (utilisation rate should be a proportion)\n",
    "print(f'revolving_util > 1: {(df[\"revolving_util\"] > 1).sum()} records')\n",
    "df['revolving_util'] = df['revolving_util'].clip(0, 1)\n",
    "print(f'  â†’ Clipped to [0, 1]\\n')\n",
    "\n",
    "# 3. Late payment counts â€” values of 96/98 are likely data entry codes, not real counts\n",
    "for col in ['late_30_59', 'late_60_89', 'late_90']:\n",
    "    n = (df[col] >= 96).sum()\n",
    "    print(f'{col} >= 96: {n} records (likely miscoded)')\n",
    "    df[col] = df[col].clip(0, 10)\n",
    "    print(f'  â†’ Clipped to [0, 10]')\n",
    "\n",
    "print()\n",
    "print(f'Final dataset shape: {df.shape[0]:,} rows x {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6",
   "metadata": {},
   "source": [
    "## Step 6: Feature Distribution Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Distribution plots by default status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "features = [col for col in df.columns if col != 'default']\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    for label, color, name in [(0, '#2ecc71', 'Non-Default'), (1, '#e74c3c', 'Default')]:\n",
    "        data = df[df['default'] == label][col]\n",
    "        axes[i].hist(data, bins=30, alpha=0.6, color=color, label=name, density=True)\n",
    "    axes[i].set_title(col, fontsize=11, fontweight='bold')\n",
    "    axes[i].legend(fontsize=8)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(features), len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Default Status\\n(Green = Non-Default, Red = Default)',\n",
    "             fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_03_feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_03_feature_distributions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7",
   "metadata": {},
   "source": [
    "## Step 7: Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Correlation heatmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "corr = df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))  # Show lower triangle only\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(\n",
    "    corr, mask=mask,\n",
    "    annot=True, fmt='.2f', cmap='RdYlGn',\n",
    "    center=0, vmin=-1, vmax=1,\n",
    "    square=True, linewidths=0.5,\n",
    "    cbar_kws={'shrink': 0.8}\n",
    ")\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_04_correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print correlation with target variable\n",
    "print('=== Correlation with Target Variable (default) ===')\n",
    "target_corr = corr['default'].drop('default').sort_values(key=abs, ascending=False)\n",
    "for col, val in target_corr.items():\n",
    "    direction = '(+)' if val > 0 else '(-)'\n",
    "    print(f'  {direction}  {col:25s}  {val:+.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8",
   "metadata": {},
   "source": [
    "## Step 8: Default Rate by Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "age-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Default rate by age band â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['age_group'] = pd.cut(df['age'],\n",
    "                          bins=[18, 25, 35, 45, 55, 65, 100],\n",
    "                          labels=['18-25', '26-35', '36-45', '46-55', '56-65', '65+'])\n",
    "\n",
    "age_default = df.groupby('age_group')['default'].mean() * 100\n",
    "avg_rate = age_default.mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "colors = ['#e74c3c' if v > avg_rate else '#3498db' for v in age_default.values]\n",
    "bars = plt.bar(age_default.index.astype(str), age_default.values,\n",
    "               color=colors, edgecolor='white', linewidth=1.5)\n",
    "plt.axhline(y=avg_rate, color='black', linestyle='--', alpha=0.7,\n",
    "            label=f'Average default rate: {avg_rate:.1f}%')\n",
    "plt.title('Default Rate by Age Group', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Default Rate (%)')\n",
    "plt.legend()\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "             f'{bar.get_height():.1f}%', ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_05_age_default_rate.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: plot_05_age_default_rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step9",
   "metadata": {},
   "source": [
    "## Step 9: Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Export cleaned data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_clean = df.drop(columns=['age_group'])\n",
    "df_clean.to_csv('cs-training-clean.csv', index=False)\n",
    "\n",
    "print('Cleaned dataset saved as: cs-training-clean.csv')\n",
    "print(f'Final shape : {df_clean.shape[0]:,} rows x {df_clean.shape[1]} columns')\n",
    "print(f'Missing values: {df_clean.isnull().sum().sum()}')\n",
    "print()\n",
    "print('=== EDA Summary ===')\n",
    "print(f'  Â· Raw data         : 150,000 rows')\n",
    "print(f'  Â· Cleaned data     : {df_clean.shape[0]:,} rows')\n",
    "print(f'  Â· Overall default rate : {df_clean[\"default\"].mean()*100:.2f}%')\n",
    "print(f'  Â· Missing value treatment : median imputation (monthly_income, dependents)')\n",
    "print(f'  Â· Outlier treatment       : age filter, revolving_util clip, late payment clip')\n",
    "print()\n",
    "print('Next step â†’ notebook_02_pd_model.ipynb: Logistic Regression PD Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ Output Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `cs-training-clean.csv` | Cleaned training dataset |\n",
    "| `plot_01_target_distribution.png` | Default rate distribution |\n",
    "| `plot_02_missing_values.png` | Missing value analysis |\n",
    "| `plot_03_feature_distributions.png` | Feature distributions by default status |\n",
    "| `plot_04_correlation_heatmap.png` | Correlation heatmap |\n",
    "| `plot_05_age_default_rate.png` | Default rate by age group |\n",
    "\n",
    "---\n",
    "**Next Notebook:** `notebook_02_pd_model.ipynb` â€” Logistic Regression PD Model (AUC, KS, Calibration)"
   ]
  }
 ]
}
